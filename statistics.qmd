---
title: "Statistics"
format: 
  html:
     code-fold: true
     code-summary: "Show the code"
number-sections: true
---

![Statistics feels like a solitary pursuit, hopefully this page helps ecologists share and learn data science skills. © Steve Markham ](Images/P1000112.jpg){fig-align="center" width="750"}


```{r}
#| include=FALSE

library(knitr)
library(tidyverse)
library(iBats)
library(gt)
library(flextable)
library(dunn.test)
library(broom)

```

Statistical tests are undertaken to improve ecological understanding, separating the single from the noise. It enhances the ecological description when writing reports, making the report more evidenced based and therefore more robust. When the data is not clear, or there is too much data to see, good statistics brings comprehension. Then there is a tendency to perceive connections or meaningful patterns between unrelated or random things, termed apophenia; here statistical testing can demonstrate it is random or unrelated.

There are many reference books for ecologists on statistics such as the gentle introductions _Statistics for Terrified Biologists_ [@emden_statistics_2008], _Practical Statistics for Field Biology_ [@fowler_practical_1998]  and _Choosing and Using Statistics: A Biologist's Guide_ [@dytham_choosing_2011]. More comprehensive guides to ecological statistics are available from _Numerical Ecology_ [@legendre_numerical_2012] and _Analysiing Ecological Data_ [@zuur_analysiing_2007]. The _Numerical Ecology with R_ [@borcard_numerical_2011] has a focus on ecological statistics using the R environment, while recent theory and application can be found in  _Ecological Statistics_ [@fox_ecological_2015].


## Summary Statistics

The Common Pipistrelle passes have been aggregated for every 30 minutes; @tbl-sum30 shows summary statistics for these bat passes during September and October. The statistics for September and October look similar and this is confirmed by the [kernel density](https://bat-survey-reporting.netlify.app/glossary#sec-kernel) plot shown in @fig-density.


```{r}
#| include: false

# https://www.r-tutor.com/elementary-statistics/non-parametric-methods/mann-whitney-wilcoxon-test


library(tidyverse) # Data Science packages - see https://www.tidyverse.org/
library(ggsci)
library(flextable)
library(officer)
library(gt)

# Install devtools if not installed 
# devtools is used to install the iBats package from GitHub
if(!require(devtools)){
  install.packages("devtools")
}

# If iBats is not installed load from Github
if(!require(iBats)){
  devtools::install_github("Nattereri/iBats")
}
library(iBats)

# Add data and time information to the iBats statics bat survey data set using the iBats::date_time_info
statics_plus <- iBats::date_time_info(statics)

agg_data <- statics_plus %>%
  filter(Species == "Pipistrellus pipistrellus") %>%
  #filter(Description == "Static 2" | Description == "Static 3") %>% 
  filter(Month == "Sep" | Month == "Oct") %>% 
  mutate(DateTime30 = lubridate::round_date(DateTime, "30 minutes"))

###
```


```{r}
#| label: tbl-sum30
#| tbl-cap: "Summary Statistics for Common Pipistrelle Passes"


Table <- agg_data  %>%
  group_by(MonthFull, DateTime30) %>% 
  tally() %>% 
  rename(Month = MonthFull) %>% 
  summarise(Min = min(n, na.rm = T),
            Q1 = quantile(n, c(0.25), na.rm = T),
            Mean = mean(n, na.rm = T),
            Median = median(n, na.rm = T),
            Q3 = quantile(n, c(0.75), na.rm = T),
            Max = max(n, na.rm = T),
            sd = sd(n, na.rm = T),
            Nr = n())
Table %>% 
flextable() %>%
  fontsize(size = 9.5, part = "all") %>% 
  width(j = 1, width = 1) %>%
  width(j = 2:9, width = 0.6) %>%
  bg(bg = "black", part = "header") %>%
  color(color = "white", part = "header") %>% 
  colformat_int(j = 9, big.mark = " ") %>% 
  colformat_double(j = c(4, 8), digits = 2)

```

Where:  

* __Min__:- Minimum value.  
* __Q1__:-  Lower quartile, or first [quartile (Q1)](https://bat-survey-reporting.netlify.app/glossary#sec-quartiles), the value under which 25% of data points are found when they are arranged in increasing order.  
* __Mean__:- Arithmetic mean of a dataset is the sum of all values divided by the total number of values.   
* __Median__:- The middle number; found by ordering all data points and picking out the one in the middle (or if there are two middle numbers, taking the mean of those two numbers).    
* __Q3__:- Upper quartile, or third [quartile (Q3)](https://bat-survey-reporting.netlify.app/glossary#sec-quartiles), is the value under which 75% of data points are found when arranged in increasing order. 
* __Max__:- Maximum value.  
* __sd__:- Standard deviation, a summary measure of the differences of each observation from the mean.   
* __Nr__:- Number of values.  


```{r}
#| label: fig-density
#| fig-cap: "Comon Pipistrelle Passes September and October"

agg_data2 <- agg_data %>% 
  group_by(MonthFull, DateTime30) %>%
  tally() %>% 
  rename(Month = MonthFull) %>% 
  ungroup() %>% 
  pivot_wider(names_from = "Month", values_from = "n")


Sep <- agg_data2 %>% 
  select(September) %>% 
  filter(!is.na(September)) %>% 
  mutate(Passes = as.numeric(September),
         Month = "September")

Oct <- agg_data2 %>% 
  select(October) %>% 
  filter(!is.na(October)) %>% 
  mutate(Passes = as.numeric(October),
         Month = "October")

Count30 <- bind_rows(Sep, Oct)

ggplot(Count30, aes(Passes, fill = Month )) +
  geom_density(alpha = 0.5) +
  scale_fill_nejm() +
  labs(x = "Passes (Number / 30 minutes)") +
  theme_bw() +
  theme(legend.position = "bottom")

```

## Comparing Two Groups

Using the [Wilcoxon signed rank test](https://bat-survey-reporting.netlify.app/glossary#sec-mw) we can decide, using a [hypothesis test](https://bat-survey-reporting.netlify.app/glossary#sec-hypothesis), whether the population distributions, summarised in @tbl-sum30 and  @fig-density are identical.  An advantage of the Wilcoxon signed rank test is that it can be undertaken without assuming the data follows the normal distribution; the density plot in @fig-density shows the data is unlikely to be normal. The two data samples for September and October need to be independent; the number of passes recorded separately in September and October are distinct populations where the passes do not affect each other.

It is assumed The survey effort (length of time the bat detectors where deployed and the locations are the same for both months)

Without assuming the data to have normal distribution, decide at .01 significance level (p < 0.01)[^3] if the observations of Common pipistrelle bats (every 30 minutes) for September and October have _identical_ data distribution.

[^3]: The significance level is always chosen before the test is undertaken.

* The null hypothesis H~0~: is that the common pipistrelle observation data for September and October are identical populations.   
* The alternate hypothesis H~1~: is that the common pipistrelle observation data of September and October are not identical populations.

To test the hypothesis, we apply the `wilcox.test` function to compare the independent samples.

```{r}
#| label: tbl-mw
#| tbl-cap: "Summary Statistics for Common Pipistrell Passes"


library(broom)

mw <- wilcox.test(Passes ~ Month, data=Count30) 

#Tidy the out put into a table
tidy(mw) %>% 
  gt() %>% 
  tab_style(
    style = list(
      cell_fill(color = "black"),
      cell_text(color = "white", weight = "bold")
      ),
    locations = cells_column_labels(
      columns = c(everything())
    )
  ) 

```




Results from the the `wilcox.test` are shown in @tbl-mw; as the [p-value](https://bat-survey-reporting.netlify.app/glossary#sec-pvalue) turns out to be `r wilcox.test(Passes ~ Month, data=Count30)$p.value`, and is not less than the .01 significance level[^1], we do not reject the null hypothesis. At .01 significance level (p < 0.01), we conclude that the common pipistrelle observation data for September and October are identical populations.

[^1]: A p-value is a measure of the probability that the observed results of a statistical test occurred by chance, given that the null hypothesis is true. In other words, a p-value helps you determine whether the results of your experiment are statistically significant. If the p-value is low (generally less than 0.05; here 0.01 is chosen), you can reject the null hypothesis and conclude that the observed differences between the groups you are studying are statistically significant.

## Comparing More Than Two Groups

### An Obvious Difference 

The `statics` data in the `iBats` package has some interesting Barbastelle (_Barbastella barbastellus_) bat activity, it would be interesting and aid  our understanding if we compare the activity between static locations and see if they are significantly different. 

Before undertaking any statistical test always visualise the data the statistical test is applied to; here the [box plot](https://bat-survey-reporting.netlify.app/glossary#sec-boxplot) is used. @fig-kwbarb shows the Barbastelle recorded at several locations.

The average bat pass rate per hour can been calculated for each night and each static location using the formula shown in @eq-aa: 

$$AverageActivity = \frac{Batpasses}{Nightlength}$$ {#eq-aa}

Where: 
_Batpasses_ = number of bat pass during the night at the location   
_Nightlength_ = length of the night in decimal hours  
_AverageActivity_ = average (mean) number of bat passes per hour for each night there was activity   




```{r}
#| label: fig-kwbarb
#| fig-cap: "Barbastelle Activity at Each Static (Nightly Average Passes per Hour)"


# Add data and time information to the statics data using the iBats::date_time_info
statics_plus <- iBats::date_time_info(statics)

# Add sun and night time metrics to the statics data using the iBats::sun_night_metrics() function.
statics_plus <- iBats::sun_night_metrics(statics_plus)


graph_data <- statics_plus %>%
    filter(Species == "Barbastella barbastellus") %>% 
    group_by(Description, Night, night_length_hr) %>%
    # count number of passes per night by species - makes coloumn "n""
    tally() %>% 
    # calculate average bat passes per hour for each Night and species
    mutate(ave_act_per_hr = n / night_length_hr) %>%
    # Remove Night Length column from the Table
    select(-night_length_hr, -n) 

ggplot(graph_data, aes(y = ave_act_per_hr, x = Description)) +
                  geom_jitter(fill = "#1f78b4", #Barbastelle colour
                              colour = "black", 
                              shape = 23, 
                              alpha = 0.7, 
                              size = 3) +
                  geom_boxplot(colour = "grey30", fill = "transparent") + 
                  labs(y = "Barbastelle Activity  \n(Nightly Average Passes per Hour)") +
                  theme_bw() + 
                  theme(legend.position = "none", # No legend
                  axis.text.x = element_text(size=12, face="bold"), 
                  axis.text.y = element_text(size=12,face="bold"), 
                  axis.title.y = element_text(face="bold"), 
                  axis.title.x = element_blank(), # no y title (just bat names)
                  panel.grid.major = element_blank(), #remove grid lines
                  panel.grid.minor = element_blank())



```

The comparison of locations is undertaken with the [Wilcoxon signed rank test](https://bat-survey-reporting.netlify.app/glossary#sec-mw) or [Kruskal-Wallis test](https://bat-survey-reporting.netlify.app/glossary#sec-kruskal). The Kruskal–Wallis test is a rank-based test that is similar to the Wilcoxon signed rank test but can be applied to one-way data with more than two groups. If there are just two locations the Wilcoxon signed rank test should be applied. The Kruskal–Wallis test may be used when there are only two samples, but the Wilcoxon signed rank test is more powerful for two samples and is preferred.  Both tests assume that the observations are independent.  The probability threshold for statistical significance, which should always be chosen before the test is undertaken, is: P < 0.05.

* __The Null Hypothesis:__ bat pass rates per hour are from distributions with the same median.

* __The Alternative Hypothesis:__ bat pass rates per hour are from distributions with a different median.

The function `kruskal.test`, from base R, is used to undertake the Kruskal-Wallis test. A rule of thumb for the Kruskal–Wallis test is each group, (in this case case the number of nightly average bats pace vales for each static location) must have a sample size of 5 or more. 

```{r}

# Add data and time information to the statics data using the iBats::date_time_info
statics_plus <- iBats::date_time_info(statics)

# Add sun and night time metrics to the statics data using the iBats::sun_night_metrics() function.
statics_plus <- iBats::sun_night_metrics(statics_plus)


test_data <- statics_plus %>%
  filter(Species == "Barbastella barbastellus") %>%
  group_by(Description, Night, night_length_hr) %>%
  # count number of passes per night by species - makes coloumn "n""
  tally() %>%
  # calculate average bat passes per hour for each Night and species
  mutate(ave_act_per_hr = n / night_length_hr) %>%
  # Remove Night Length column from the Table
  select(-night_length_hr, -n)


# Check at least 2 locations and a minimum of 5 observations per location
# Only do KW on locations with 5 or more observations
# if just two locations do Mann Whitney
check_data <- test_data %>%
  group_by(Description) %>%
  tally()

# filter for Statics with more than 5 values
StaticsWithPlus5 <- check_data %>%
  filter(n >= 5) %>%
  pull(Description)

test_data <- test_data %>%
  filter(Description %in% StaticsWithPlus5)

# Extract the p-value from the kruskal.test
stat_pvalue <- kruskal.test(ave_act_per_hr ~ Description, data = test_data)$p.value

```

With reference to @fig-kwbarb there are several static locations where the activity can be compared, this is more than two locations, therefore the Kruskal-Wallis test is undertaken rather than the Mann-Whitney-Wilcoxon test. Location 1 with only three results is excluded from the test.   

The Kruskal-Wallis test  undertaken for the Barbastelle at the following static locations: `r knitr::combine_words(StaticsWithPlus5)` produced a P value (`r formatC(stat_pvalue, format = "e", digits = 2)`) less than the chosen threshold for statistical significance of 0.05; therefore the null hypothesis is rejected, activity between some static locations is likely to be different.   

What the Kruskal-Wallis test does not indicate, is which static locations are different; to determine this we need to undertake _post hoc_ testing, this can be undertaken with the [Dunn’s Test](https://bat-survey-reporting.netlify.app/glossary#sec-kruskal).  

```{r}
#| include: false

dunn_result <- dunn.test(test_data$ave_act_per_hr, factor(test_data$Description), method = "bonferroni")

```

```{r}
#| eval: false
library(dunn.test)

dunn_result <- dunn.test(test_data$ave_act_per_hr, factor(test_data$Description), method = "bonferroni")

```


Results of the Dunn’s test, performed after the Kruskal-Wallis test (_post hoc_), are shown in @tbl-dunns.


```{r}
#| label: tbl-dunns
#| tbl-cap: "Results of Post-hoc testing with the Dunn’s Test"


df <- tibble(dunn_result$comparisons, dunn_result$P.adjusted)

colnames(df) <- c("Comparison", "P.adj")

resultsTable <- df %>%
  filter(P.adj < 0.05) %>%
  select(`Locations with a significant difference (P<0.05)` = Comparison, `adjusted P ` = P.adj)

resultsTable %>%
  flextable(col_keys = colnames(.)) %>%
  fontsize(part = "header", size = 12) %>%
  fontsize(part = "body", size = 12) %>%
  bold(part = "header") %>%
  autofit(add_w = 0.1, add_h = 0.1) %>%
  bg(bg = "black", part = "header") %>%
  color(color = "white", part = "header") %>%
  align(align = "center", part = "header") %>%
  align(j = 2, align = "right", part = "body") %>%
  bold(j = 1, bold = TRUE, part = "body")     
```

The Dunn’s Test carries out multiple comparisons therefore a P value adjustment needs to be made to avoid a false significant result. For this P value adjustment the Bonferroni method is applied; a simple technique for controlling the overall probability of a false significant result when multiple comparisons are to be carried out.

@tbl-dunns gives the results of the _post hoc_ testing with the Dunn’s test and shows that Barbastelle activity at Location 4 is significantly different (at P<0.05) to activity at Locations 2, 3, and 5.  

The statistical tests show that Barbastelle bat activity recorded at Location 4 is significantly different; this knowledge is evidence based and can be stated with confidence when reporting. 


### Less Obvious Difference 

@fig-kwpip shows Common pipistrelle activity for the static locations comparison of activity can be undertaken with the Kruskal-Wallis test with the following hypothesis:

* __The Null Hypothesis:__ bat pass rates per hour are from distributions with the same median.

* __The Alternative Hypothesis:__ bat pass rates per hour are from distributions with a different median.

```{r}
#| label: fig-kwpip
#| fig-cap: "Common Pipistrelle Activity at Each Static (Nightly Average Passes per Hour)"


# Add data and time information to the statics data using the iBats::date_time_info
statics_plus <- iBats::date_time_info(statics)

# Add sun and night time metrics to the statics data using the iBats::sun_night_metrics() function.
statics_plus <- iBats::sun_night_metrics(statics_plus)


graph_data <- statics_plus %>%
    filter(Species == "Pipistrellus pipistrellus") %>% 
    group_by(Description, Night, night_length_hr) %>%
    # count number of passes per night by species - makes coloumn "n""
    tally() %>% 
    # calculate average bat passes per hour for each Night and species
    mutate(ave_act_per_hr = n / night_length_hr) %>%
    # Remove Night Length column from the Table
    select(-night_length_hr, -n) 

ggplot(graph_data, aes(y = ave_act_per_hr, x = Description)) +
                  geom_jitter(fill = "#ffff99", #Common Pipistrelle colour
                              colour = "black", 
                              shape = 23, 
                              alpha = 0.7, 
                              size = 3) +
                  geom_boxplot(colour = "grey30", fill = "transparent") + 
                  labs(y = "Common Pipistrelle Activity  \n(Nightly Average Passes per Hour)") +
                  theme_bw() + 
                  theme(legend.position = "none", # No legend
                  axis.text.x = element_text(size=12, face="bold"), 
                  axis.text.y = element_text(size=12,face="bold"), 
                  axis.title.y = element_text(face="bold"), 
                  axis.title.x = element_blank(), # no y title (just bat names)
                  panel.grid.major = element_blank(), #remove grid lines
                  panel.grid.minor = element_blank())



```


```{r}

# Add data and time information to the statics data using the iBats::date_time_info
statics_plus <- iBats::date_time_info(statics)

# Add sun and night time metrics to the statics data using the iBats::sun_night_metrics() function.
statics_plus <- iBats::sun_night_metrics(statics_plus)


test_data <- statics_plus %>%
  filter(Species == "Pipistrellus pipistrellus") %>%
  group_by(Description, Night, night_length_hr) %>%
  # count number of passes per night by species - makes coloumn "n""
  tally() %>%
  # calculate average bat passes per hour for each Night and species
  mutate(ave_act_per_hr = n / night_length_hr) %>%
  # Remove Night Length column from the Table
  select(-night_length_hr, -n)


# Check at least 2 locations and a minimum of 5 observations per location
# Only do KW on locations with 5 or more observations
# if just two locations do Mann Whitney
check_data <- test_data %>%
  group_by(Description) %>%
  tally()

# filter for Statics with more than 5 values
StaticsWithPlus5 <- check_data %>%
  filter(n >= 5) %>%
  pull(Description)

test_data <- test_data %>%
  filter(Description %in% StaticsWithPlus5)

# Extract the p-value from the kruskal.test
stat_pvalue <- kruskal.test(ave_act_per_hr ~ Description, data = test_data)$p.value

```
The Kruskal-Wallis test undertaken for the Common pipistrelle at the following static locations: `r knitr::combine_words(StaticsWithPlus5)` produced a P value (`r formatC(stat_pvalue, format = "e", digits = 2)`) less than the chosen threshold for statistical significance of 0.05; therefore the null hypothesis is rejected, activity between some static locations is likely to be different. The Dunn’s test can be applied to determine the static locations that are different. 


```{r}
#| include: false

dunn_result <- dunn.test(test_data$ave_act_per_hr, factor(test_data$Description), method = "bonferroni")

```

```{r}
#| eval: false

dunn_result <- dunn.test(test_data$ave_act_per_hr, factor(test_data$Description), method = "bonferroni")

```


Results of the Dunn’s test, performed after the Kruskal-Wallis test (_post hoc_), are shown in @tbl-dunns2.


```{r}
#| label: tbl-dunns2
#| tbl-cap: "Results of Post-hoc testing with the Dunn’s Test"


df <- tibble(dunn_result$comparisons, dunn_result$P.adjusted)

colnames(df) <- c("Comparison", "P.adj")

resultsTable <- df %>%
  filter(P.adj < 0.05) %>%
  select(`Locations with a significant difference (P<0.05)` = Comparison, `adjusted P ` = P.adj)

resultsTable %>%
  flextable(col_keys = colnames(.)) %>%
  fontsize(part = "header", size = 12) %>%
  fontsize(part = "body", size = 12) %>%
  bold(part = "header") %>%
  autofit(add_w = 0.1, add_h = 0.1) %>%
  bg(bg = "black", part = "header") %>%
  color(color = "white", part = "header") %>%
  align(align = "center", part = "header") %>%
  align(j = 2, align = "right", part = "body") %>%
  bold(j = 1, bold = TRUE, part = "body")     
```

@tbl-dunns2 gives the results of the _post hoc_ testing with the Dunn’s test; post P value adjustment with the Bonferroni method showing:

* Common pipistrelle activity at static 4 is significantly different (at P<0.05) to all the other static locations.  
* Common pipistrelle activity at static 1 is significantly different to static locations 2, 3 and 4.  The significant difference (at P<0.05) between static 1 and static 3 is not easily determined from @fig-kwpip.  
* Common pipistrelle activity at static 2, static 3, and static 5 are not significantly different (at P<0.05).

## Bootstrap Confidence Intervals

@tbl-barbstat5 gives summary statistics for Barbastelle (_Barbastelle barbastellus_) pass observations per night at Static 5. 

```{r}
#| label: tbl-barbstat5
#| tbl-cap: "Barbastelle Observations (Passes) at Static 5"
#| warning: false

# Libraries (Packages) used
library(tidyverse)
library(mosaic)
library(gt)
library(gtExtras)
library(iBats)
library(infer)

# Add data and time information to the statics data using the iBats::date_time_info
statics_plus <- iBats::date_time_info(statics)

# Group by Description and Night and Count the Observations
barb_static5 <- statics_plus %>% 
  filter(Species == "Barbastella barbastellus", Description == "Static 5") %>% 
  group_by(Description, Night) %>% 
  tally() 

# The summary statistics are saved into a variable riven_cond_stats 
cond_stats <- favstats(n~Description, data = barb_static5)

# riven_cond_stats is made into a the table (using the code below)
cond_stats %>% 
  # Create the table with the gt package
  gt() %>% 
  # Style the header to black fill and white text
  tab_style(
    style = list(
      cell_fill(color = "black"),
      cell_text(color = "white", weight = "bold")),
    locations = cells_column_labels(
      columns = c(everything())
    )
  ) %>% 
  #gt_color_rows(median, palette = "ggsci::yellow_material") %>% 
  tab_options(data_row.padding = px(2)) 

```

For Static 5 there is a mean of __`r  round(cond_stats$mean, digits = 2)`__ passes per night for the 23 nights the bat detector was deployed. It is valuable to know the confidence of this mean number of passes observed.  The population of passes, the number of Barbastelle's passes for every night in history, is not available; in practice there is only the sample of data and not the entire population. The [bootstrap](https://bat-survey-reporting.netlify.app/glossary#sec-boot) is a statistical method that allows us to approximate the sampling distribution (and therefore confidence intervals) even without access to the population.

In bootstrapping the sample itself becomes the _population_. Samples from the _population_ are drawn many times over and every time from all the _population_. This process is called re-sampling with replacement and creates a bootstrap distribution. The `infer` package has functions for re-sampling with replacement and estimating confidence limits. 

```{r}

# bootstrap the number of Barb pass 1000 time and calculate the mean 
bootstrap_distribution <- barb_static5 %>% 
  specify(response = n) %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "mean")

#calculation the 95% confidence intervals
percentile_ci <- bootstrap_distribution %>% 
  get_confidence_interval(level = 0.95, type = "percentile")

```

The 95% confidence interval is computed by piping `bootstrap_distribution` into the `get_confidence_interval()` function from the `infer` package, with the confidence level set to 0.95 and the confidence interval type to be "percentile". The results are saved in `percentile_ci`.

The 95% confidence interval is the middle 95% of values of the bootstrap distribution, the 2.5^th^ and 97.5^th^ percentiles, which are `percentile_ci$lower_ci` = __`r round(percentile_ci$lower_ci, digits = 2)`__ and `percentile_ci$lower_ci` = __`r round(percentile_ci$upper_ci, digits = 2)`__, respectively. This is known as the percentile method for constructing confidence intervals.

The confidence interval (__`r round(percentile_ci$lower_ci, digits = 2)`__, __`r round(percentile_ci$upper_ci, digits = 2)`__) can be visualized, see @fig-bootBarb5,  by piping the `bootstrap_distribution` data frame into the `visualize()` function and adding a `shade_confidence_interval()` layer. The endpoints argument are set to the `percentile_ci`.

```{r}
#| label: fig-bootBarb5
#| fig-cap: "Boostrap Distribution of the Mean Barbastelle Observations (Passes) at Static 5"

visualize(bootstrap_distribution) + 
  shade_confidence_interval(endpoints = percentile_ci)

```

The bootstrapping of confidence intervals can be used for all the factors in a description (e.g. static locations), the month of activity or the species observed. The code below creates @tbl-specobs; confidence intervals for nightly species observations (passes) where there is more than 10 bat observations (passes) for the species in total. @fig-boot illustrates the mean nightly species observations with _error bars_ indicating the confidence intervals.


```{r}
#| label: tbl-specobs
#| tbl-cap: "Nightly Species Observations (Passes) Mean and 95% Confidence Intervals"

#List species with more than 10 passes observed
SpeciesList <- statics_plus %>%
  group_by(Species) %>% 
  count() %>% 
  filter(n > 10)

SpeciesList <- levels(factor(SpeciesList$Species))

Table_ci <- NULL #blank data.frame for table

for(BatName in SpeciesList) {

  
  night_obs <- statics_plus %>% 
    #filter(Species == "Pipistrellus pipistrellus", Description == static) %>% 
    #group_by(Description, Night) %>% 
    filter(Species == BatName) %>% 
    group_by(Species, Night) %>% 
    tally() 
  
  # Calculate the mean
  species_mean <- mean(night_obs$n)
  
  # bootstrap the number of Barb pass 1000 time and calculate the mean 
  bootstrap_distribution <- night_obs %>% 
    specify(response = n) %>% 
    generate(reps = 1000, type = "bootstrap") %>% 
    calculate(stat = "mean")
  
  #calculation the 95% confidence intervals
  species_ci <- bootstrap_distribution %>% 
    get_confidence_interval(level = 0.95, type = "percentile")
  
  species_ci$mean <- species_mean
  
  species_ci$species <- BatName
  
  Table_ci <- rbind(Table_ci, species_ci)
  
}

Table_ci %>% 
  # round numbers to 1 decimal place
  mutate(mean = round(mean, digits = 1),
         lower_ci = round(lower_ci, digits = 1),
         upper_ci = round(upper_ci, digits = 1)) %>% 
  #Arrange descending for readability
  arrange(desc(mean)) %>% 
  # configure column headings
  select(Species = species, Mean = mean, `Lower 95% ci` = lower_ci, `Upper 95% ci` = upper_ci) %>% 
  gt() %>% 
  # Style the header to black fill and white text
  tab_style(
    style = list(
      cell_fill(color = "black"),
      cell_text(color = "white", weight = "bold")),
    locations = cells_column_labels(
      columns = c(everything())
    )
  ) %>% 
    # Make bat scientific name italic
  tab_style(
    style = list(
      cell_text(style = "italic")
      ),
    locations = cells_body(
      columns = c(Species)
    )
  ) %>% 
  tab_footnote(
    footnote = "Species with more than 10 bat observations (passes) in total",
    locations = cells_column_labels(
      columns = Species
    )) %>% 
  tab_options(data_row.padding = px(2)) 

```

```{r}
#| label: fig-boot
#| fig-cap: "Nightly Species Observations (Passes)  and 95% Confidence Intervals (error bars)" 

graph_bat_colours <- iBats::bat_colours_default(Table_ci$species)

Table_ci %>% 
  ggplot(aes(x=reorder(species, mean), y=mean, fill=species)) + 
    geom_bar(position=position_dodge(), stat="identity") +
    geom_errorbar(aes(ymin=lower_ci, ymax=upper_ci),
                  width=.2,                    # Width of the error bars
                  position=position_dodge(.9)) +
  scale_fill_manual(values = graph_bat_colours) +
  coord_flip() +
  labs(
    y = "Mean Nightly Species Observations") +
  theme_bw() +
  theme(
    legend.position = "none", # No legend
    axis.text.x = element_text(size = 10, angle = 0, face = "bold"),
    axis.text.y = element_text(size = 10, face = "bold.italic"), # bat names italic
    axis.title.y = element_blank(), # no y title (just bat names)
    axis.title.x = element_text(size = 10), # no x title
    panel.grid.major = element_blank(), # remove grid lines
    panel.grid.minor = element_blank(),
    panel.border = element_blank(),
    panel.grid.major.x = element_line(colour = "grey20", linewidth = 0.1, linetype = "dashed")
  )


```



## Bat Assemblage

The assessment of individual species ignores the fact there is also the species assemblage; the taxonomically related group of species (i.e. bats) occupying the same geographical area at the same time. The assemblage of bat species can be explored using __multivariate methods__.

For most surveys the number of species observed is greater than one, making it a biological assemblage. We can relate this assemblage to other factors such as _location, habitat, time, weather, etc._
Multivariate analysis gives a way of exploring the bat assemblage differences with respect to factors such as the location/habitat or month/year or combination of both.

### Cluster Analysis

@tbl-table04 shows a summary matrix of bat passes per species for each static (i.e. location)  We would like to know which locations are similar/dissimilar. 


```{r}
#| label: tbl-table04
#| tbl-cap: "Matrix of Location by Species"


Tab_L_S <- statics %>% # Location - Species
  group_by(Species, Description) %>% 
  count() 

maxValue <- max(Tab_L_S$n, na.rm = T)

Tab_L_S <- Tab_L_S %>% 
  pivot_wider(names_from = Species, values_from = n) %>% 
  replace(is.na(.), 0)

ncols <- ncol(Tab_L_S)

#Make coloured palette
colourer <- scales::col_numeric(
  palette = c("transparent", "forestgreen"),
  domain = c(0, maxValue))

Tab_L_S %>% 
  flextable() %>% 
    bold(part = "header") %>% 
    bg(bg = "black", part = "header") %>% 
    color(color = "white", part = "header") %>% 
    rotate(j = 2:ncols, rotation = "tbrl", align = "center", part = "header") %>% 
    height_all(height = 2.3, part = "header") %>% 
    hrule(rule = "exact", part = "header") %>%
    bg(bg = colourer, j = 2:ncols, part = "body") %>%
    width(j = 2:ncols, width = 0.4) %>% 
    width(j = 1, width = 0.8)

```


In multivariate analysis the [pre-treament](https://bat-survey-reporting.netlify.app/glossary#sec-pretreatment) of data (sometimes in more than one way) is usually desirable. For assemblage data, _transformations_ will reduce the dominant contribution of abundant species (i.e. all those pips). Transformations include (None, Square root, Fourth root, Log(X+1), Presence/absence). @tbl-table05 shows @tbl-table04 transformed with the species $\sqrt[2]{count}$.

```{r}
#| warning: false
#| label: tbl-table05
#| tbl-cap: "Transformed Matrix"

SpeciesC <- Tab_L_S %>% 
  ungroup() %>% 
  select(2:ncol(.)) %>% 
  mutate_all(funs(sqrt(.)))

Table <- SpeciesC %>% 
  mutate_all(funs(round(., 2)))

Matrix <- Tab_L_S %>%
  ungroup() %>% 
  select(Description) %>% 
  bind_cols(SpeciesC)


MatrixTable <- Tab_L_S %>%
  ungroup() %>% 
  select(Description) %>% 
  bind_cols(Table)

Matrix <- data.matrix(Matrix[, 2:ncol(Matrix)])

r_names <- Tab_L_S %>%
  ungroup() %>% 
  pull(Description)

rownames(Matrix) <- r_names

# Number of columns in table
ncols <- ncol(MatrixTable)

#Make coloured palette
colourer <- scales::col_numeric(
  palette = c("transparent", "forestgreen"),
  domain = c(0, maxValue))

MatrixTable %>% 
  flextable() %>% 
    bold(part = "header") %>% 
    bg(bg = "black", part = "header") %>% 
    color(color = "white", part = "header") %>% 
    rotate(j = 2:ncols, rotation = "tbrl", align = "center", part = "header") %>% 
    height_all(height = 2.3, part = "header") %>% 
    hrule(rule = "exact", part = "header") %>%
    bg(bg = colourer, j = 2:ncols, part = "body") %>%
    width(j = 2:ncols, width = 0.4) %>% 
    width(j = 1, width = 0.8)

```

To assess the differences of activity (in the bat assemblage) between locations (or months, habitat, etc.) we measure the distance between every point of activity with every other point. So activity (e.g. a median or count) at one location for a species is compared(measured) with every other activity for all the species and locations.

There are many _distance_ measurements to investigate species similarity/dissimilarity^[note it is the dissimilarity that is used, 1- similarity] for more information see the [Glossary](https://bat-survey-reporting.netlify.app/glossary#sec-distance).   

In this example the [Bray-Curtis](https://bat-survey-reporting.netlify.app/glossary#sec-bray) distance measurement has been applied to @tbl-table05 to produce the Bray-Curtis dissimilarity matrix in @tbl-table06.

(For species similarities it may be worth considering the removal of the rarer species (_i.e. the less observed_) and repeating the analysis.)

```{r}
#| warning: false
#| label: tbl-table06
#| tbl-cap: "Bray-Curtis Dissimilarity Matrix"

library(vegan)

dist_bray <- vegdist(Matrix, method="bray")

dist_df <- tibble(dist_bray)

fmt2 <- function(dist_num) {
  
  temp <- as.character(dist_num)
  
  stringr::str_sub(temp, 1L, 7L)
  
}

c1 <- c("Static 2", "Static 3", "Static 4", "Static 5")
c2 <- c(fmt2(dist_df[1,1]), fmt2(dist_df[2,1]), fmt2(dist_df[3,1]), fmt2(dist_df[4,1]))
c3 <- c(" ", fmt2(dist_df[5,1]), fmt2(dist_df[6,1]), fmt2(dist_df[7,1]))
c4 <- c(" ", " ", fmt2(dist_df[8,1]), fmt2(dist_df[9,1]))
c5 <- c(" ", " ", " ", fmt2(dist_df[10,1]))

dist_tbl <- tibble(c1, c2, c3, c4, c5)

colnames(dist_tbl) <- c(" ", "Static 1", "Static 2", "Static 3", "Static 4")

ft <- dist_tbl
ncols <- ncol(ft)

ft %>% 
  flextable() %>% 
    bold(part = "header") %>% 
    bold(j=1, part = "body") %>% 
    bg(bg = "black", part = "header") %>% 
    bg(j=1, bg = "black", part = "body") %>% 
    color(color = "white", part = "header") %>% 
    color(j=1, color = "white", part = "body")
    
```



The Bray-Curtis dissimilarity matrix can be used in many multivariate methods; here the matix is used in [Hierarchical Clustering](https://bat-survey-reporting.netlify.app/glossary#sec-cluster). Hierarchical clustering is useful because it can create a tree-based representation of the observations called a dendrogram; that is easy to interpret visually.  The [dendrogram](https://bat-survey-reporting.netlify.app/glossary#sec-dendrogram) from the Bray-Curtis dissimilarity matrix in @tbl-table06 is shown in @fig-graph21. 

```{r}
#| label: fig-graph21
#| fig-cap: "Dendrogram Between Static Locations"

# Hierarchical cluster function hclust
hc_bray <- hclust(dist_bray, method = "complete")

# Always visualse
library(ggdendro)
#Creates Dendrogram Plot Using ggplot.
ggdendrogram(hc_bray, rotate = TRUE, size = 2) +
  labs(title = "Static Location - Complete Cluster - Bray-Curtis")

dhc <- as.dendrogram(hc_bray)


```


Clustering refers to a very broad set of techniques for finding subgroups, or _clusters_, in a data set.  Clustering involves grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters). Referring to the dendrogram in @fig-graph21 the lower in the tree fusions occur, the more similar the groups of observations are to each other. While observations that fuse later, near the top of the tree, can be considered less similar.  

For @fig-graph21 we can see that for the bat assemblage:  

* Statics 3 & 2 are similar
* Statics 1 & 5 are similar
* Static 4 is more similar to Statics 2 & 3 than Statics 1 & 5
* Statics 2 & 3 and Statics 1 & 5 are more similar to Static 4 -  than Statics 2 & 3 and Statics 1 & 5 are to each other   


Note, the dendrogram is illustrative and we cannot draw conclusions about the degree of similarity of two observations based on their proximity along the vertical axis.

This is just an introduction to _Hierarchical Clustering_, there are many variations and other types of clustering (e.g. _k-means_). Key variations for hierarchical clustering are:

* distance measurement used e.g.  Bray-Curtis, Euclidean, etc.
* type of linkage e.g. complete, average, single or centroid.

### K-Means Clustering

[K-means clustering](https://bat-survey-reporting.netlify.app/glossary#sec-kmeans) is a simple approach for partitioning a data set into **_K_** distinct non-overlapping clusters. To perform **_K_** means clustering we must specify the desired number of clusters first.  The code below applies k-means clustering to the Bray-Curtis dissimilarity matrix in @tbl-table06 with **_K=2_**.

```{r}
#| code-fold: show

result_km <- kmeans(dist_bray, centers = 2)
```


```{r}
#| label: tbl-kmcluster
#| tbl-cap: "k-means Cluster and Location"

clusters <- tibble(names(result_km$cluster), result_km$cluster)

colnames(clusters) <- c("Location", "Cluster")

clusters %>% 
  gt() %>% 
  tab_style(
    style = list(
      cell_fill(color = "black"),
      cell_text(color = "white", weight = "bold")
      ),
    locations = cells_column_labels(
      columns = c(everything())
    )
  ) %>% 
  cols_width(everything() ~ px(150))
```

```{r}
#| label: tbl-kmtidy
#| tbl-cap: "Summary on a Per-Cluster Level"

tidy(result_km) %>% 
  gt() %>% 
  tab_style(
    style = list(
      cell_fill(color = "black"),
      cell_text(color = "white", weight = "bold")
      ),
    locations = cells_column_labels(
      columns = c(everything())
    )
  )

```


```{r}
#| label: tbl-kmglance
#| tbl-cap: "k-means Overall Summary Statistics"
glance(result_km) %>% 
  gt() %>% 
  tab_style(
    style = list(
      cell_fill(color = "black"),
      cell_text(color = "white", weight = "bold")
      ),
    locations = cells_column_labels(
      columns = c(everything())
    )
  )
```



The output of `kmeans` is a list of information; the most important:

* `cluster`: @tbl-kmcluster & @tbl-kmtidy A vector of integers (from 1:K) indicating the cluster to which each point is allocated.
* `centers`: A matrix of cluster centers.
* `totss`: @tbl-kmglance The total sum of squares.
* `withinss`: @tbl-kmtidy Vector of within-cluster sum of squares, one component per cluster.
* `tot.withinss`: @tbl-kmglance Total within-cluster sum of squares, i.e. sum(withinss).
* `betweenss`: @tbl-kmglance The between-cluster sum of squares, i.e. $totss-tot.withinss$.
* `size`: The number of points in each cluster.
* `iter`: @tbl-kmglance The number of (outer) iterations.


```{r}
#| include: false

# https://www.tidymodels.org/learn/statistics/k-means/
```


### Non-metric Multidimensional Scaling (NMDS)


[Non-metric Multidimensional Scaling](https://bat-survey-reporting.netlify.app/glossary#sec-NMDS) is an ordination technique that reduces dimensionality in multivariate data sets such as the count of bats in @tbl-NMDScount.  Dimensionality reduction simply refers to the process of reducing the number of attributes in a dataset while keeping as much of the variation in the original dataset as possible. The goal of NMDS is to collapse information from multiple dimensions (e.g, from multiple communities, sites, etc.) into just a few, so that they can be visualized, (e.g. as a 2D or 3D plot), and interpreted.

Unlike other ordination techniques that rely on (primarily Euclidean) distances, such as Principal Component Analysis (PCA), NMDS uses rank orders, and thus is an extremely flexible technique that can accommodate a variety of different kinds of data [@clarke_non-parametric_1993], [@Krobertclarke1999Nonmetric:7dd2]; NMDS does require at least one observation per factor (e.g. site or month). In R, the `metaMDS()` function of the `vegan` package can execute a NMDS. As input, it expects a community matrix with the factors as rows and the species as columns; @tbl-NMDScount has two factors, static location and month, that are treated separately. 

Before undertaking ordination it is best to transform the data; this helps reduce the influence of large counts from dominant species (i.e. Common pipistrelles). @tbl-NMDS4throot is @tbl-NMDScount transformed with  $\sqrt[4]{count}$.

A measure of how successful the NMDS reduction is stress[^6]. The lower the stress value, the better the ordination. A rule of thumb for stress values:

* stress < 0.05 provides an excellent representation in reduced dimensions
* stress < 0.1 is great, 
* stress < 0.2 is good, 
* stress > 2.0 < 0.3 interpret with caution
* stress > 0.3 provides a poor representation.


[^6]: NMDS reduces the rank-based differences between the distances between objects in the original matrix and distances between the ordinated objects. The difference is expressed as stress. 

@fig-NMDSplots-1 shows the two dimensional plot after the NMDS is applied through `metaMDS()` function to the transformed data shown in @tbl-NMDS4throot; the NMDS produced a _good_ stress of 0.14. @fig-NMDSplots-2 is the [Shepard plot](https://bat-survey-reporting.netlify.app/glossary#sec-Shepard) showing the scatter around the regression between the interpoint distances in the final configuration (i.e., the distances between each pair of communities) against their original dissimilarities; the desirable outcome from the Shepard plot is a diagonal line with limited scatter in this respect @fig-NMDSplots-2 looks reasonable.

@fig-NMDSlabelplots shows the 2D @fig-NMDSplots-1: with @fig-NMDSlabelplots-1 labelled for static location and @fig-NMDSlabelplots-2 labelled for month (@fig-NMDSlabelplots-2).

```{r}
#| label: tbl-NMDScount
#| tbl-cap: "Count of Species by the Meta Data; Location and month"

library(tidyverse)
library(glue)
library(ggthemes) # for colour pallet "Tableau 10"
library(flextable)
library(iBats)
library(vegan)

# Add data and time information to the statics data using the iBats::date_time_info
statics_plus <- iBats::date_time_info(statics)

# Count of bat species by location and month
description_month_count <- statics_plus %>% # Location - Species
  group_by(Species, Description, Month) %>% 
  count() %>% 
  pivot_wider(names_from = Species, values_from = n) %>% 
  replace(is.na(.), 0)

# Number of columns in table
ncols <- ncol(description_month_count)

description_month_count %>% 
  flextable() %>% 
    bold(part = "header") %>% 
    bg(bg = "black", part = "header") %>% 
    color(color = "white", part = "header") %>% 
    rotate(j = 3:ncols, rotation = "tbrl", align = "center", part = "header") %>% 
    height_all(height = 2.3, part = "header") %>% 
    hrule(rule = "exact", part = "header") %>%
    width(j = 3:ncols, width = 0.4) %>% 
    width(j = 1:2, width = 0.8)


```


```{r}
#| label: tbl-NMDS4throot
#| tbl-cap: "Count of Species with Data Transformed by 4th Root"


species_count <- description_month_count[, 3:ncol(description_month_count)]
meta_data <- description_month_count[, 1:2]

Transformed_Data <- (species_count)^(1/4)

# Number of columns in table
ncols <- ncol(Transformed_Data)

Transformed_Data %>% 
  flextable() %>% 
    bold(part = "header") %>% 
    bg(bg = "black", part = "header") %>% 
    color(color = "white", part = "header") %>% 
    rotate(j = 1:ncols, rotation = "tbrl", align = "center", part = "header") %>% 
    height_all(height = 2.3, part = "header") %>% 
    hrule(rule = "exact", part = "header") %>%
    width(j = 1:ncols, width = 0.4) %>% 
    colformat_double(digits = 3)

```


```{r}
#| include=FALSE


# Nonmetric Multidimensional Scaling (NMDS), 
# and tries to find a stable solution 
# using several random starts
nMDS_results <- metaMDS(Transformed_Data, distance = "bray")

# extract NMDS scores (x and y coordinates) for plotting
nMDS_coords = as.tibble(scores(nMDS_results)$sites)

# bind the factors (static location and month back)
graph_data <- bind_cols(meta_data, nMDS_coords)

```

```{r}
#| eval: false
#| code-fold: show


# Nonmetric Multidimensional Scaling (NMDS), 
# and tries to find a stable solution 
# using several random starts
nMDS_results <- metaMDS(Transformed_Data, distance = "bray")

# extract NMDS scores (x and y coordinates) for plotting
nMDS_coords = as.tibble(scores(nMDS_results)$sites)

# bind the factors (static location and month back)
graph_data <- bind_cols(meta_data, nMDS_coords)

```

```{r}
#| label: fig-NMDSplots
#| fig-cap: "Non-metric Multidimensional Scaling Solution and Stress Plot" 
#| fig-subcap: 
#|   - "Unlabeled Solution of NMDS (2D)"
#|   - "Stress Plot "
#| layout-ncol: 2


graph_style <- theme_bw() + 
  theme(legend.position = "none", # No legend
  axis.text.x = element_text(size=12, angle = 270, face="bold"), # text bold and vertical
  axis.text.y = element_text(size=12, face="bold.italic"), # bat names italic
  strip.text = element_text(size=12, face="bold"), # Bold facet names
  axis.title.x = element_blank(), # currently not used
  axis.title.y = element_blank(), # no y title (just bat names)
  panel.grid.major = element_blank(), #remove grid lines
  panel.grid.minor = element_blank(),
  plot.caption = element_text())

g1 <- ggplot(graph_data, aes(x = NMDS1, y = NMDS2)) + 
    geom_point(size = 9, colour = "dodgerblue", alpha = 0.8) +
    scale_x_continuous(expand = c(0.05, 0.05)) +
    scale_y_continuous(expand = c(0.05, 0.05)) +
    labs(caption = glue("Stress {round(nMDS_results$stress, digits = 2)}")) +
    graph_style

g1
stressplot(nMDS_results)


```


```{r}
#| label: fig-NMDSlabelplots
#| fig-cap: "Non-metric Multidimensional Scaling Solution and Stress Plot" 
#| fig-subcap: 
#|   - "Labelled by Static Location"
#|   - "Labelled by Month"
#| layout-ncol: 2



graph_style <- theme_bw() + 
  theme(legend.position = "none", 
  axis.text.x = element_text(size=12, face="bold"),
  axis.text.y = element_text(size=12, face="bold"), 
  strip.text = element_text(size=12, face="bold"), 
  axis.title.x = element_blank(), 
  axis.title.y = element_blank(), 
  panel.grid.major = element_blank(), 
  panel.grid.minor = element_blank(),
  plot.title = element_text(size=16, face="bold"))

p1 <- ggplot(graph_data, aes(x = NMDS1, y = NMDS2, label=Description)) + 
    geom_point(size = 9, aes(colour = Description), alpha = 0.8) +
  geom_text(size = 5) +
  scale_color_brewer(palette = "Set2") +
  scale_x_continuous(expand = c(0.05, 0.05)) +
  scale_y_continuous(expand = c(0.05, 0.05)) +
  labs(title = "Static Location") +
  graph_style

p2 <- ggplot(graph_data, aes(x = NMDS1, y = NMDS2, label=Month)) + 
    geom_point(size = 9, aes(colour = Month), alpha = 0.8) +
  labs(title = "Month") +
  geom_text(size = 5) +
 scale_fill_tableau(palette = "Tableau 10") + 
  scale_x_continuous(expand = c(0.05, 0.05)) +
  scale_y_continuous(expand = c(0.05, 0.05)) +
  graph_style


p1
p2
```



#### ANOSIM

The [ANOSIM test](https://bat-survey-reporting.netlify.app/glossary#sec-ANOSIM) is similar to an ANOVA hypothesis test; it uses a dissimilarity matrix as input instead of raw data. It is also non-parametric, meaning it doesn’t assume much about the data, a useful attribute for the often-skewed ecological data. As a non-parametric test, ANOSIM uses ranked dissimilarities instead of actual distances, and for this reason complements an NMDS plot. The main point of the ANOSIM test is to determine if the differences between two or more groups are significant. 

The function `anosim` from the package `vegan` can test whether there is a statistical difference between groups (e.g. static locations or months)

* null hypothesis - no differnce 
* alternative - difference 

The higher the `R` value (it has a range 0 to 1), __the more dissimilar your groups[^7] are in terms of bat assemblage__. @fig-anosimPlots-1 shows the ANOSIM result for the Static Locations, there is a statistical difference of the bat species assemblage for the static location.  @fig-anosimPlots-2 shows the ANOSIM result for the Month, there is no statistical difference of the bat species assemblage for the Months.

[^7]: The test to determine which individual group is different (e.g. Static 1, Static 2 ...), is not available in R; it can be undertaken in the Primer-E software <https://www.primer-e.com/>.


```{r}
#| label: fig-anosimPlots
#| fig-cap: "ANOSIM: Test is there a Statistical Difference Between Groups" 
#| fig-subcap: 
#|   - "ANOSIM Static Location"
#|   - "ANOSIM Month"
#| layout-ncol: 2
#| warning: false

graph_style <- theme_bw() + 
  theme(legend.position = "none", 
  axis.text.x = element_text(size=12, face="bold"),
  axis.text.y = element_text(size=12, face="bold"), 
  strip.text = element_text(size=12, face="bold"), 
  axis.title.x = element_blank(), 
  axis.title.y = element_blank(), 
  panel.grid.major = element_blank(), 
  panel.grid.minor = element_blank(),
  plot.caption = element_text(size = 12),
  plot.title = element_text(size=16, face="bold"))

Factor <- "Static Location"

ano = anosim(Transformed_Data, 
             meta_data$Description, 
             distance = "bray", 
             permutations = 9999)

#Tjis is how PrimerE views ANOSIM Results
Rperms<- tibble(ano$perm)

Rstat <- ano$statistic
sigValue <- ano$signif

if(sigValue < 0.05) {
  
  SigText <- glue("ANOSIM significamce value ({sigValue}) for {Factor} is statistically significant at P<0.05")
  
} else {
  
  SigText <- glue("ANOSIM significamce value ({sigValue}) for {Factor} is not statistically significant at P<0.05")
  
}

colnames(Rperms) <- c("Rano")

p1_description <- ggplot(Rperms, aes(Rano)) +
  geom_histogram(fill = "dodgerblue") +
  geom_vline(xintercept = Rstat, colour = "gold3", linewidth = 2, linetype = "dashed") +
  annotate("text", x = Rstat, y = 300, label = glue("R statistic \n {round(Rstat, digits = 3)}")) +
  labs(title = Factor,
       y = "Frequency",
       x = "R",
       caption = SigText) +
  graph_style


Factor <- "Month"

ano = anosim(Transformed_Data, 
             meta_data$Month, 
             distance = "bray", 
             permutations = 9999)

#Tjis is how PrimerE views ANOSIM Results
Rperms<- tibble(ano$perm)

Rstat <- ano$statistic
sigValue <- ano$signif

if(sigValue < 0.05) {
  
  SigText <- glue("ANOSIM significamce value ({sigValue}) for {Factor} is statistically significant at P<0.05")
  
} else {
  
  SigText <- glue("ANOSIM significamce value ({sigValue}) for {Factor} is not statistically significant at P<0.05")
  
}

colnames(Rperms) <- c("Rano")

p2_month <- ggplot(Rperms, aes(Rano)) +
  geom_histogram(fill = "dodgerblue") +
  geom_vline(xintercept = Rstat, colour = "gold3", linewidth = 2, linetype = "dashed") +
  annotate("text", x = Rstat, y = 300, label = glue("R statistic \n {round(Rstat, digits = 3)}")) +
  labs(title = Factor,
       y = "Frequency",
       x = "R",
       caption = SigText) +
  graph_style

p1_description
p2_month

```

